import { ReadableStream } from 'node:stream/web'
import type { LLMProvider, Messages, Reader } from './types'

const TEST_DATA = `
ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§ã™ğŸ¤–

# è¦‹å‡ºã—1
## è¦‹å‡ºã—2
### è¦‹å‡ºã—3
#### è¦‹å‡ºã—4
##### è¦‹å‡ºã—5

ã“ã‚Œã¯é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚

**å¤ªå­—ãƒ†ã‚­ã‚¹ãƒˆ**

*æ–œä½“ãƒ†ã‚­ã‚¹ãƒˆ*

~~å–ã‚Šæ¶ˆã—ç·šãƒ†ã‚­ã‚¹ãƒˆ~~

- ãƒªã‚¹ãƒˆé …ç›®1
- ãƒªã‚¹ãƒˆé …ç›®2
    - ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒªã‚¹ãƒˆé …ç›®1
    - ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒªã‚¹ãƒˆé …ç›®2
- ãƒªã‚¹ãƒˆé …ç›®3

1. ç•ªå·ä»˜ããƒªã‚¹ãƒˆé …ç›®1
2. ç•ªå·ä»˜ããƒªã‚¹ãƒˆé …ç›®2
    1. ãƒã‚¹ãƒˆã•ã‚ŒãŸç•ªå·ä»˜ããƒªã‚¹ãƒˆé …ç›®1
    2. ãƒã‚¹ãƒˆã•ã‚ŒãŸç•ªå·ä»˜ããƒªã‚¹ãƒˆé …ç›®2
3. ç•ªå·ä»˜ããƒªã‚¹ãƒˆé …ç›®3

> ã“ã‚Œã¯å¼•ç”¨ã§ã™ã€‚
> è¤‡æ•°è¡Œã«æ¸¡ã‚‹å¼•ç”¨ã®ä¾‹ã§ã™ã€‚

\`ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰\`

\`\`\`
ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§ã™ã€‚
è¤‡æ•°è¡Œã«ã‚ãŸã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚
\`\`\`

[ãƒªãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆ](https://example.com)

![ç”»åƒã®ä»£æ›¿ãƒ†ã‚­ã‚¹ãƒˆ](https://via.placeholder.com/150)

---

ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä¾‹ã§ã™ã€‚

| å•†å“å  | ä¾¡æ ¼    |
|---------|---------|
| ã‚Šã‚“ã”  | Â¥100    |
| ã¿ã‹ã‚“  | Â¥80     |
| ãƒãƒŠãƒŠ  | Â¥120    |

Pythonã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§ã™ã€‚

\`\`\`python
def hello():
    output = "Hello, World!"
    print(output)

if __name__ == "__main__":
    hello()
\`\`\`

TypeScriptã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§ã™ã€‚

\`\`\`ts
interface Person {
  name: string;
  age: number;
  isStudent: boolean;
}
\`\`\`
`
const CHUNK_SIZE = 5
const MAX_CHUNKS = (TEST_DATA.length / CHUNK_SIZE) * 3

function createDummyStream(): ReadableStreamDefaultReader<Uint8Array> {
  let index = 0
  let chunkCount = 0

  const stream = new ReadableStream<Uint8Array>({
    async pull(controller) {
      let chunk = ''
      for (let i = 0; i < CHUNK_SIZE; i++) {
        chunk += TEST_DATA[index]
        index = (index + 1) % TEST_DATA.length
      }
      const data = {
        id: `${chunkCount}`,
        model: 'dummy',
        choices: [{ delta: { content: `${chunk}` }, finishReason: null }],
        usage: null,
      }
      const payload = `data: ${JSON.stringify(data)}\n`
      controller.enqueue(new TextEncoder().encode(payload))
      chunkCount++

      await new Promise((resolve) => setTimeout(resolve, 25)) // delay

      if (chunkCount >= MAX_CHUNKS) {
        controller.enqueue(new TextEncoder().encode('data: [DONE]\n'))
        controller.close()
      }
    },
  })

  return stream.getReader()
}

export class TestProvider implements LLMProvider {
  async chatStream(
    _messages: Messages[],
    _temperature?: number | null,
    _maxTokens?: number | null,
  ): Promise<Reader> {
    await new Promise((resolve) => setTimeout(resolve, 1000)) // delay
    return createDummyStream()
  }
}
